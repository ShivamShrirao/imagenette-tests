{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tiny-Imagenet-test",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJbYXou6chZf",
        "outputId": "c77c3cdf-3964-42b2-c249-0d289d08f9de"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb 24 01:37:12 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuLVd2r7HA9V",
        "outputId": "c18f4d20-aceb-46a0-8c8d-ddcc65a08e1c"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twOQl22KFY1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d2eeda-ed90-4b8a-9900-9d38ed28034d"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-24 21:54:38--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  19.6MB/s    in 19s     \n",
            "\n",
            "2021-02-24 21:54:57 (12.5 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wRBn4wJ4Dj1"
      },
      "source": [
        "!unzip -q tiny-imagenet-200.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2F1iqzV4M8c",
        "outputId": "c8b4da79-c7b0-4423-9ed7-4b39af120b87"
      },
      "source": [
        "!git clone https://github.com/ShivamShrirao/tiny-imagenet-test"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tiny-imagenet-test'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 17 (delta 4), reused 14 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PjLOoEn4YJn",
        "outputId": "a5ce7e1b-b185-4e45-9adc-31df1c208c29"
      },
      "source": [
        "%cd tiny-imagenet-test"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tiny-imagenet-test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdzeFNwL1V94"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axyqhY9PF96o"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import glob\n",
        "import os\n",
        "import csv\n",
        "from tqdm.notebook import tqdm\n",
        "from time import time\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXklA82Nacy8"
      },
      "source": [
        "# tf.keras.backend.set_image_data_format('channels_first')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA-8kxs3F_Na"
      },
      "source": [
        "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "# policy = mixed_precision.Policy('mixed_float16')\n",
        "# mixed_precision.set_policy(policy)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T3HHJJlExFr"
      },
      "source": [
        "img_height, img_width = 64, 64\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0V-TC4tOdzr"
      },
      "source": [
        "TRAIN_PATH = \"../tiny-imagenet-200/train/\"\n",
        "TEST_PATH = \"../tiny-imagenet-200/test/\"\n",
        "VAL_PATH = \"../tiny-imagenet-200/val/\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZVuqDMKz9_F"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k1gaCqwcPm3"
      },
      "source": [
        "class_names = np.array(sorted([fp.split('/')[-1] for fp in glob.glob(TRAIN_PATH+\"*\")]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75V6qFuo99If"
      },
      "source": [
        "val_labels = {}\n",
        "with open(VAL_PATH+\"val_annotations.txt\") as fIn:\n",
        "    reader = csv.reader(fIn, delimiter='\\t')\n",
        "    for row in reader:\n",
        "        val_labels[row[0]] = row[1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sXKYelt2sIy"
      },
      "source": [
        "def get_train_label(file_path):\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "    one_hot = parts[-3] == class_names\n",
        "    return tf.argmax(one_hot)\n",
        "\n",
        "def get_val_label(file_path):\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "    name = parts[-1].numpy().decode()\n",
        "    one_hot = val_labels[name] == class_names\n",
        "    return tf.argmax(one_hot)\n",
        "\n",
        "def decode_img(file_path):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [img_height, img_width])\n",
        "    img = img/255.0\n",
        "    return img\n",
        "\n",
        "def process_train_path(file_path):\n",
        "    label = get_train_label(file_path)\n",
        "    img = decode_img(file_path)\n",
        "    return img, label\n",
        "\n",
        "get_val_label_wrapper = lambda x: tf.py_function(get_val_label, [x], tf.int64)\n",
        "\n",
        "def process_val_path(file_path):\n",
        "    label = get_val_label_wrapper(file_path)\n",
        "    img = decode_img(file_path)\n",
        "    return img, label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOynOo4Rb2_I"
      },
      "source": [
        "train_list_ds = tf.data.Dataset.list_files(TRAIN_PATH+\"*/images/*\", shuffle=True\n",
        "            ).map(process_train_path, num_parallel_calls=AUTOTUNE\n",
        "            ).cache()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ7QkS8T2Kg5"
      },
      "source": [
        "val_list_ds = tf.data.Dataset.list_files(VAL_PATH+\"images/*\"\n",
        "            ).map(process_val_path, num_parallel_calls=AUTOTUNE\n",
        "            ).cache()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFw_6JpFyNC"
      },
      "source": [
        "mean = []\n",
        "std = []\n",
        "for a,b in train_list_ds.take(1024):\n",
        "    mean.append(a.numpy())\n",
        "    std.append(a.numpy())\n",
        "mean = np.asarray(mean).mean(axis=(0,1,2)).reshape(1,3,1,1)\n",
        "std = np.asarray(std).std(axis=(0,1,2)).reshape(1,3,1,1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q4fgsU6G2im",
        "outputId": "0aceee7c-aa6b-4d10-ac77-486b4b2a4614"
      },
      "source": [
        "mean.ravel(), std.ravel()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.47657734, 0.45386508, 0.3950202 ], dtype=float32),\n",
              " array([0.27600715, 0.26707038, 0.2805239 ], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2QO5jISLB-W"
      },
      "source": [
        "mean = tf.convert_to_tensor(mean)\n",
        "std = tf.convert_to_tensor(std)\n",
        "def channel_first_and_normalize(img, lbl, mean=mean, std=std):    # over batches\n",
        "    img = tf.transpose(img, perm=[0,3,1,2])\n",
        "    img = img - mean\n",
        "    img = img / std\n",
        "    return img, lbl"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL_7xW3ltw_2"
      },
      "source": [
        "def augment(img_lbl, seed):         # over individual image\n",
        "    img, lbl = img_lbl\n",
        "    # Make a new seed\n",
        "    new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]\n",
        "    # Random Contrast\n",
        "    img = tf.image.stateless_random_contrast(img, 0.5, 1, seed)\n",
        "    # Hue\n",
        "    img = tf.image.stateless_random_hue(img, 0.05, new_seed)\n",
        "    # Saturation\n",
        "    img = tf.image.stateless_random_saturation(img, 0.4, 2, seed)\n",
        "    # Random brightness\n",
        "    img = tf.image.stateless_random_brightness(img, 0.2, new_seed)\n",
        "    img = tf.clip_by_value(img, 0, 1)\n",
        "    return img, lbl"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp8qY0tst1uM"
      },
      "source": [
        "rng = tf.random.Generator.from_seed(123, alg='philox')\n",
        "# A wrapper function for updating seeds\n",
        "def augment_wrapper(x, y):\n",
        "    seed = rng.make_seeds(2)[0]\n",
        "    img, lbl = augment((x, y), seed)\n",
        "    return img, lbl"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1re3yRBL7czJ"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([                       # over batches\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomHeight(0.3),\n",
        "    layers.experimental.preprocessing.RandomWidth(0.3),\n",
        "    layers.experimental.preprocessing.RandomTranslation(0.3,0.3),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.12),     # 0.12 * 2pi = 43.2 deg\n",
        "    layers.experimental.preprocessing.Resizing(img_height, img_width)\n",
        "])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lUQgyTmBVrJ"
      },
      "source": [
        "# PIL.Image.fromarray((a*255).numpy().astype(np.uint8))\n",
        "# c,_ = augment((a,None), rng.make_seeds(2)[0])\n",
        "# c = data_augmentation((c[None,...]), training=True)[0]\n",
        "# PIL.Image.fromarray((c*255).numpy().astype(np.uint8))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qlqkGeMt1kX"
      },
      "source": [
        "train_ds = (\n",
        "    train_list_ds\n",
        "    .map(augment_wrapper, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "    .map(channel_first_and_normalize, num_parallel_calls=AUTOTUNE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn9eVO36Jk64"
      },
      "source": [
        "val_ds = (\n",
        "    val_list_ds\n",
        "    .batch(BATCH_SIZE)\n",
        "    .map(channel_first_and_normalize, num_parallel_calls=AUTOTUNE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBSmxgPeMxNf",
        "outputId": "3303d627-d9db-4e3c-9544-4fb904092c8d"
      },
      "source": [
        "a, b = next(iter(train_ds))\n",
        "a.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 3, 64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZB4ZTQxbMxI1",
        "outputId": "eda203d0-dd0f-455c-c4ed-b97926caac6d"
      },
      "source": [
        "idx = np.random.randint(0,128)\n",
        "x = a.numpy()[idx]\n",
        "z = (x-x.min())/(x.max()-x.min())\n",
        "z = z.transpose(1,2,0)\n",
        "class_names[b[idx]]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'n03649909'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERq3KyCzfIAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "126133dd-dc34-41a8-dfe5-a59861303e59"
      },
      "source": [
        "PIL.Image.fromarray((z*255).astype(np.uint8))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAbbklEQVR4nFV6WZIkOZKdbgDMzD22zKqsqqzq7pnmnIJH4Rl4ZA7Z0j1dS66x+GIGqOrjh0XOkPETYhEuLgZAofo2/h//878XLcJC4AhHQk2JGQwgEskKFhIhLcyCRES6RxCnKqkQUQKUQRGcIcLVdIpBl8smMIJdzyslH5bDZJMGa4oyC0PNSp2YCtM0T/djIzi/e/PWOLKfFVs1Ang4MsUDEfDECASIRJhFiUyEiYmIiJCRmSkqIszMSSzMzMRCoizMoKDXHwAAmAivz8QERnISeaQPys7ugUgOKVIsS6E6lVahygwEMRkKcyUqPBidBVZkLuybX5E03PsYw0msspiICkEBJBELQBFpzMz87RW+rYSZwWBiImYm5v0XEX1b7P5nZhATEkkEAQRgSklwDqJQDianKqXZNOk067Lo1LgIEdLBxKJMJVFjy9i4zY1TfES/DkRnGlvvYGlSVAQsyIgAwGbGzGu/GPO3t2JiEQH+8yWJ+XV/QUhA9v8wETMxsRBxRGZAWAnGJAwhGELJScnUTNWq1qp1Km0u88StUWECSRBTEgPqKes6vFO5kTG27fyyXa+cnSgiUouampl5wj3GcJC0ZTazy/n0/5/At8rYH1+fEkRgEIhECd9WR8QJ6pv78FZNRQkqYkj1QRlUtDWdJpsLWWGbaqtWLUVThYhYkoBEJGdg6z2TQWNdx+XynL6ZkrKolFJKbdWKxToyPXyQiCqZEZEbANBeLZRAJiQTIBCBCCAABCSFgpWYGPvHQJkAQKrVnSJT2JjEndYeGcyVLYmCi9qirdkkIggA6ZGJJBawAHJdt/PldLy5Jfbz5bKuZ6E0q3VqxXSa6zRVjxxjHWPdz36MK6BqZJlg2feYRUREmIWZCdhvScJBCcpMBokIgYiJsS8FatLgApcIDg+HpJrUSlYZxWAVVqAGcc/1cuWRyqqlsBCbEnFEWLE21YjIDA+niFqKWmlLPRxnZI6tu3dVqqWQCDDcvRSxzGQSVWYWIWZOImYSer0cTGAmziQAJPsFAFiYiImZNLzQUB7ia/YeVLQcZ63NpDS0GfOUZiScrz0hIonJamMWJokI92itmZqPUUq5ub1FeCuFVZmFRTychadl0mJqxZGRyUxMYplQISZh1kREEEAGBjMTqVQhTQRhcJKmiXCAieL1KqeNzdBFu/iKcC5Wmk4qpZAupR15biEYAUBV5jb1YCSpmlhJkr6t7n6cZmUOojZNh2ViIMMjPBJ9RARKbVba1geIOYLTiZiUbN9FIomg4bQNiICUmEnFlI0lfQxOZiYjYwhyeHAiwUKohLKtTqsrtGiZZGpR2ckS88GWuQnTSATSyKwUqpRJIlZq88AYjoC9dhprrc3L0moZfbucL4TwIIKqNY9IBDGXYoISEa1NVm1h0nCOoD64DxYWFVFRNWMmRGAQgsVEUJAUg8MpAWJJsr5i3bKK3R7uDvMyaV1sotV5+HwV5oQwm3K+tji1Ymwk6oGtD4+wUkqtxUxVSy1arE5tmqf5cADAICSs1oioU2dmUdm27bpe5+Vgmo1YkYJIAU1lMjGFkhOTEjMDylULrGgg18t6WbOPBCAqSehOUqZpPhzuHo42LVRvqeb52k8nvm4ewkvl2UpRTpIUUhVrarWPcVl7a9PheHj79o2qAdGmdnN7rLWqiooyC4GRlIl1XdUGy37/NMGq1SgqUeFkdapS5uNiWsY2IkJ1BxpIyiD3jMt6fTnH9RpjgAAiT0qt03J7kDavARq9sjLAzyM+X7galcoLW6llKpVVUxJmbalten5+uVy3u7v2/bvv7+5vVYQItdVSS2Qys5ZiWoQtg7dtYwlWUhVmqEVtpKomdBAqxCqmU5nvbx+K1ev5GplSFIwO32Lb1svz9eX5Ms6X7BtFMALhTiyHOwGXy8jnl8c2mOvthKCv58uX8+FmKT+UMs3lcJiP81Imgya0zEdR24aX2o7Hw9vv3h6W2UxLMVFZ+9Yv1wSSGSRMkk7b5h77jGUAzKyqzGxzeygyTWWedJq0zXU2sawQUxhfxvrl9PR43T4/X7+cLpe+jQDIQOw+fJCq1JSXa7/61tf1kLZM5YZV1jEcxDrNh8P9Q31znJZp1tqkik7Slst1HQ5imZdDaxOzqKqajdHX67b1ASISTYyxbWOLsQ0RUhMiAAlkhAOw0m5up7v7w92xHiqbpAoxq3CRNcfV43ztn76+fD5fLhmbcJCQkGd0ApiUYRnDx2V0YpqKboxTeGG0u+ObX97f//hufvMgh6YmwsZSkiQ81823HvNyc//wptYmTMUKEuu6jTEAiFlpDaDz5eSbU6I1q8VAmR5AuHcC2enqhypm01SXJkWCCUyCYALGZd2+Pr88nk/XGBvHRsHGpU7WCrXifWTkSlkpp5tDa22hQm6nU6jlrPoptykGJWxEJa3FhlMgiHBdx9b95jiXUsMzKTshkaMPMyUVYqm1ilptF0RkxIhNepqKKpWiyMrM9unxuel8u9zdVOAVlSIyA9l7P51PX58fz+tlWAzynl5KnW4PU21M3Nft+em599EJx5vj3d1tTbGNXLZBiGAtoevJz/MBy2FSjiFsWipBeiCJ5+UgomP0vddEeoRXqyLikSpSaqmtRN8ginTvmxQrU1MrSsLM9un50UhvpuNNW8woQQxKwuDYfDuv59PltG5rCCdnZpLwcjh89/13t7e3fe3/+Md/fPr0ae0rVKxVDiJjFB2TDE9pqtJlvZAWxeg52rzczKU7zpcVLMvhyCKZKUyUCQ/OJKQQc0aOkWrCrMLCArbuW3oISETFhIjstJ4/Bh4OxzfHYzuwJVGChFIpd2rVtxiDazWTIqYQZbu/e/jLX/7CImLFGb/98dvj6YmYjGWurdSCVkbvw3DzsKxBA3RdR24DbNPIx6fT3//291ZNS7Fakd6YNIMpWYDs7pQjO6l7UmRhIcTwEBA8owfpzgLYuvfTyMt6DvKUxE5UhMWkcW21cMKSNVWTKBkr+vM2Tt5s/un9+1YOp237dHq8nE/pUbWcWqGqaKrVClwvX3X6bo6eHo0kIx4/f/r99w/np8eHX94zwZHELETog3pnzZ7RR9JgTeOUSYTqBKRMCxFt2wYQE5uaqhonee99DC1apmJJPlxN6zzB7e54993dmzHSOwpVRgQ4Xvz06XT9us5/Wt6/+/mvf/23U17+9r//PS6bZ0Sndbv2FYeHu7vj8auvdXuG4R7tQecytu3p6eX58eY4LVPb1tXhmmFgWT2dMJmrXWLNyyDvRyptbmzmGTvGVzUkVMXMRMQUUlUnq7W2eZ4F5C8nUZ2mCUPf3j38+ac/weXr83M4MekI4Jwvfzx/+vuHj/cf6nF6e//2X//bX7v3x98/Y4vw8HULp/K2zocjB17cJS+B0KIm5eLb19NpKs0Tp8uVnSuRQqcU0sVFu9I5Y6ybhB9KSoFUTuYEMpNpJyyyc3VrsDfH27f3b+c61do4CTgDzKTGuDve/uWnPxnsP3794+vzS0cqMjr1x8vHv//+71xu3t5NP9388MOPg/JD++365eXyeFrPvXF50+5nW6giVn/ZBoEUlbVdJT/1Xq653K3DxJxn5SpTtQNbW0Evw89uY/AEuKePIawplEB47FpIRianENtBl1/evf/53fulLtEjRzA4PbbrCqIm5e3d/VSm2+Pd3/7xz8+PT1v4yKBgfzx9pn+O8/n7wy/z/e1P73+5qTeXD0+f/vFHPztXe2g3/RIv1zMiJzVRIb8+n+N6WS9tupXDx2u/cixHyake52kj8p5fR3zsl20bJYRUPHPzrmJilhE+YqeK2FUrM/vzDz//+f0vd4cbAWV3QpowgBh9p73KdJhb3N9u26aq162vYyOhqVQdPl5Ol0+P7365r8vN8U2x2+9/fvPDMh8+fPrEneY2ffn69Xw+5/GgR9vG1f3UV8zL3d27Px0ofX28xjiUumk+ffrw5ePpmnLqnXzcEW+H+VqC6jRpmVsb24gRrxQdIJCw2J/e//z9m7fNDO5jnyajgyCMiIwEsQRImA7L/OBR17WumoTaihZhwvb16cvffq1vbpZ5+e7hrTy8q6XVf/8/zy+n8+N1PPXcMhVR4OzrGNFJpK++3bXCKu7j+XKK63b+9Pz8xxMGcvXSAyzrYT7z23L3o7aiZgiUUnJntyAiUlV7uLttxZDh7pQpQkRJQEaEh3uCeCSGu6ke5omFRRBIq2pVSWlc169/+7U93doP32e7OT68+fnnnzfPX//5e/TPS5ktdNG5hJJH7ZkOy/Ml/3mpzWK7jJdniULCzxs9n6dTny9+DJnJ5Hyh2yr0I5tlIjOFmV4JAYUHE5uK+BhJQDhT1lJUNTOZXmWiSHhEeDJxrTUJoAgEK1kRMHz0/ukc5+2pQ10YMt3dvP/5vWiZ6lK5vHx9qqqW5GuPK2RzGyv9/vHsMKKXWE80zPReyturf/d4+e4S39FkMl0gsXpJysA2emw9IwFSVWYCKAPm7tdLmLApF1VmCU/3aM2KGeAUaawk6ZGcHlBw8eSAA5ER6N26k9Mpv4zVQfxT+5c3bx/U6jwtN8vhP/7X37YvT/U69MnlcdPzxa7P9PLFtvA0Mh5GXiWndnD65ep/vtKbZCr61ObnlNxyu24+EiNGH0RkthNeI9AubMk3NG7FLCMIomLETJyiYsKMFI1YgwBVIeb07H3btnXbNjhU6/CMyKfDMt/etK0/ns7X9Xq5PI/zM319rE/99rnfPI/by7jpXU+XGPSY+K2Ya3TDwfV7Kz9s9K7jmDE414QGzi/nUbixzqXN87Su27Z1MxOW67iame0zmUUSBHApkxmx8HAXNi0WoHVbRaSYeqgQRe/ho2/rtl761ik4GdFdha+PL5//+Xt8+PR0OQ0fpw+f+4cP88eX2+fx/sI/XPn7Ffdblis2sj+kEuR566d1zDrdHQ4L2Did+Uy5GkeV1ft2vaZaVRMtosoRCYwx3MPMiqqalaKKiEzmYqYaEUBasdLa5s69C5GZTag9tjVz9G30LcIJGZ4AcZ0kCOt4+fDl7P3p/By9++dH+fXLzeP6w5X/MsrPm7zrcbeFdbmYidlnxpKxhRfHJJPWukm+UD4WOR+tH8ooMig1IoG986CUzL1Dkpkpk5iVaZrSPcaIgKgkkojNiqqJh4gAMBXmEttA5ugj3BmkqkkQ1WmeSm0FMi6bX07j69c4nfXz0+2nlx+v+FfUf3H6cY2H7ofeJdRYFkZRtxJFSZigdSz1KeNk8bVRfzPjpsZSuBinsiqJqAiYyYOYVfbyBrFILRVmGwhAeGSCiSMi1rX3kRFAsLKZSmcCGKAEAcJUp3Z782Y+3GibpNrmI5LX0xZ/PM0fn365xr9R/Svo/Xq5X9elbzacqLJaKLy4LNakspYT09fSXOly4PNt8TdHbiqqpbZJqtZK8s1yESlqImoEEuIYfrlcKDMjmNjhrzZM+K6FTrWI1uHbiFCV1tqyLGBkepva1A5zu7E669QC6OuWL9fytC6P2w+r/Bu1vwb/2Mfd9bL0s2EQq9vh0tqT9pNC7g/zciBanm3R+YZaG4vmYrkUlqophVTFSIVEPSKJWDRA4W7MpMyE9N6ZgAR/c2t2jR0gJqpWrZr7lhHFys3NUZSsqIfPy3RcbqsdSApU17HF1sfTSZ6uh7P/4PZnrj8Ov9/G0kcJB2ETPU/zlzZ9Ir9oKcfb8vAgumz17mW6U6tcTSarVchUU7LHyDFEQzIjaR+2CQJZNVU1BBCxay6vvhIRZYBe/SVhCJMwE8iKaVl2dO7eSymt1LlMydYJlBjX3p+vdt4OG76DvEXebX3ZevEAqVu91sPXZfnY6mP0mKd2fMDdA9VltONWDlWqiVpRrcKFE+lbF9BQY2ZKMAsyGayq1moxtdGHRzJAADMLK5CJXVwSMSUg3UXEzIQ5iQSiJEkCz9hcDMzgjOw+zquft7rlkeQWNG1r2a4yeoBD21rn58PNx3n+YHyWRe8nvbnPw82oza1mKcxFIKZaTMmo55a7L5JJxARCDAK11syKqYgwKVMyMgIRYHZ0evWZoMYqvMMKZSlqkd7X7fJyvp7OTNTmVisrIhMSGdsYl04DzdpxpnLd3NdBviqBba31eZo+FvtV/APjOhe6O/LNIoeZVZGsxYoUdZhKMUsJAZtorUVEfTiBRh/CMjXOSAMyA0ykIsTpACJ3nwaAirZpVjPPSAcSzYo7b37N1WXQMrWH+fawLCzUkYW5sClX5uYUMdVh5XFszJiSw+zSpk9qv2F8Zbocp7xbcDfzXLkVhpiVWqsEEwJgIJggQiPjernYoRS18+mSiTrVjPR0y9gtGTYr1eqQ3rexm5jhySzChSDhkZksoiwkMNbCpnW6nQ+383GqxTPch0KnMt0c7q/zqZ/8ieRzqT7PZ6Qmu+mpyCflj0rjWORupvsFy6RTYysSJBCKpCAGRYQ7qQqYAukjorlYVdVadGoTM2d0Q2SSMJOJqVrI7ggbgZkSoHBiRSYlyFiIdsWVixqLzm0qVpQURAYCl8M0P7zB5cv69HT9uF6b8bkUK8aBTfna9GWe18Nkd4sshefGtZpVFVNScWaH7PptIsFMDGYwRWIMN62lVFMzK0yUkpZJrw1TQYnRM0MSjASL7v6GENGuJcluNcd+IEqvPHW3e4qYlaXZFF7O32/Xx9NL77/GeGFSU1IaJnl7wNs39va+Hae+XVO5lla1Fm7FCiUqpKl5JCuTSDKBiURJKCIzoWoAZWZRU1FT0UxKgAPBENFalMFJKSKsTEIRkchpaqXa5XRar+v5fLlcLsqszEpE02SqVVpdbl3rdcPbd98r0ZelnH7755bDWi1VaZnqd2/s+7f14a62opezskzzXG02ssJVlApJM3XVoAiBZzoRs7ZWKCVGalVEJidkl69ERSgD4cmcZoZAjHy1g0RZOZEIhAcI7n69Xi+Xy7ZtnKAIE6mlKIOZx7atNECx3M5W39VGT7Ph/CLprMyt6v2N3t/qMivLtFgTrVaVlYLViZOAGJHaTGsZHJFDmGub59I0RMA7/GcWYVEVU1UQEdIzSGkHbUGxrts0NVUlJhGR149BRCLSx+64BQN+cBEpxVTEM8Ahmm0xLW1sS/Q7uZ2VkJmpQnPjUmubDqXaFpZkrAJGkhCbqTAnJ5uSCjMLgQizLcf5gO4x3D1UVFl4J/X/GRwgfg1wiEpIAmAWEQFDmHU3m/YgAn9LVzCraanFzEo1Zk5CVYmggQDSKtelVmrGPIY7ECpMUllmq9SHEhVW3rMCTKUUNU2lVAQTg4VBkRIqIZGMJAaLChNnAAiLiD0YofragFS0VFqWuRSjVzC04yOER++DiVVNZIjIzc3N/f1dKa+xHVO2atFjXDdGtirerLAIBCzYZakE9TGwyoCKiSqDwUlEyWAjnSoLIQORGoQx+su2DiFOULIwExMo3JEwoj3HQczMzAACwUy1tt1VT4pAZCYRAfm68Sp7SuRwWO4fHkwYicQOnGAMpQgfQlGLCkRImTWykw/OzN63zMkmqUYqu4uYSEcqaNJKqtkjQQzOnuvWLaQtJRmITGJh2ZuhuTuQIkrgyNjPSEkzk3jPRICIIjI9tEgphUVAFBEe8fz88unTp5vDodZGoqJKxEJURIPGyCSQe9ZSrKiMgL+y8tqMlLtE7KCF96MhjLg8dzFTMYEg4H3EOjDNIprIyITgtdpFDMgdJ2VASFmEiRO5l5aakH6jBhGsJMJ74CMyvY/n5xch6nd3D2/fzstUygQmRmcQBcIzE57EDjMmVS2lNJ2XJiYDSE5H7rEkJgKTR/TN1cphPpTdAmDe9ysjIXvWbM8rSRE1ItobS3iyMCszMWKHfiT7GKTX5QK0J6YAZMQY4xQeoxNwON4uBxMqmUBwDkQgA69fQ5wg1lJV2mzzYQqMbRskhEghfIuOfOsN8lqjrKLFsqYUhRAR7ZkUEmaSYmYAqUr4Dp5fZdM9Q7YPPCICQ1RrkUjf1uHumRGRHu49KWJdtkgAOjZExljDe6YjAwCpFSuVWDSTWEq1Ugwe+H/eW4iFmIiqymE+1HkiEBxsrE2Jy3y3lGZjbJmZGSrCQlrUMjOCQDAzJgmPQHJ+u9O7EiCwYlpk67tfGJmvC2aAiPcAFJK2dfSxXa9bIOm13e7f9A3gZGzXKEqsMJYMKIntin8CCVGZrLUyebgjAg4lXazdzabMK8boPnxEV9XIMCLqvYtoLVVZv83gnVVyRDCxqOxa5LZtEUHfBoKwsLKoJIAMIgKISVQ14zVaRJQRAyATQ2bf1s7JcC0CkqpaxIyECUAycyvV2Kh7xkBGZiQ7CV3GyUJ963tReoSIJNKIaAw3IyrEIixAIiLCU1U9XFmFhAAPH31kpuzJKGK88v4I98gghlWx1qCDusNFnTXZPQBWK5RId1BsG2mISSFNNVJiCmSQMLGT5+ZIUiIlIJIchNP6IsnsKFpeY2NCYLIdWxIwdCjv3h+7u48gQniI/lfSkkX2KKnIN4k404liB++IUptVSykhml1tSKREhDCUkZQMgCgCYqJs5LnrCEhkJIg6eiLBqc2IiOBMmZTr5vCsVFT0m8vEmWF9l3wTY4xiRXaNgoiAXX5h5r2caqkLLXv3MTN9jamxiBBTpkf2apMUqLOljhQxkWAzVubwEWMwAURBtMzTXJc4b5nhvMcMsQsJwiTC8PCI5BADGB6OSDIjRmYISyIyYd+GsKiqqlIyMddSUrRYiQwSTiAiZac8xXSYmZVSuikxV9N5mlprgI9xTR7gCGQPl1IMPPpKQHh3dxBIGSadcPZNyJWgLCScAmFNkABK5L0nggurCoE5c4xOWlVlWzf3SMwmavM0XdfrDidFZO8wLKIkLCykJEREyOxbd7iKtlb7VkoppiaKt2/f/PzTj/f3t8WYcqTTzkXICjH6ZWx9JJgTMXpEBimSs2+Dh/Yue9hZjVWELSPZUXb/PkOYuZAo8X/1dxIREaiImZoVM7ddCHolvkx7fedO6URYKSnH6AG3YoV2PdislCJ8d3f75s2DqfDrgMtkDQhJJULSGo5YVxpjrOvIQCuMJQgQxrbma/xhKtJ079uZzGbfQsP7jCYW0R3CpKq9egFqBpCZMVNkZnRlVX0FxumxVzm/vhvwOh+EWUSlFDMRIvYIQiobi6ZjZLozYAAI6qtfvzzF5Rx9DYIcpiIwZa0WY+vbVVG5mqIqsTIzs4kqCCBRJqbXbTcDcUTWUmX3iVnMh1tRZh4jEJCi++0kRO4jiBigXfBSUybaT2lPyQJ4eTl9LnZ/ezNPr/mKNbNHBiuAHHR6fHn67UNcTgLnYpWhx8PezlnE1IqVprWyFbZiJoQqQplBTMZgJIFYWBRJSDBxRo5IFf2/zbJZ8qYhFwAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F3765F55810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKexFaR-GJ6A"
      },
      "source": [
        "config_defaults = {\n",
        "    'activation'            : 'leaky_relu',\n",
        "    'dp_rate'               : 0.2,\n",
        "    'batch_size'            : BATCH_SIZE,\n",
        "    'norm'                  : 'bn',\n",
        "    'self_attn'             : True,\n",
        "    'frac_dk'               : 0.5,\n",
        "    'frac_dv'               : 0.25,\n",
        "    'pos_emb'               : True,\n",
        "    'optimizer'             : 'adamw',\n",
        "    'min_lr'                : 2e-6,\n",
        "    'max_lr'                : 8e-4,\n",
        "    'weight_decay'          : 2e-5,\n",
        "    'clr_step_size'         : 8,\n",
        "    'loss_function'         : 'cce',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieZR_Zwq5fZE"
      },
      "source": [
        "class AttributeDict(dict):\n",
        "    __slots__ = () \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTdSfqgL52JZ"
      },
      "source": [
        "CONFIG = AttributeDict(config_defaults)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgMX_ZXm4JPO"
      },
      "source": [
        "import model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPugCFtx4JMp"
      },
      "source": [
        "model.CONFIG = CONFIG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lchAuU1s4JKO"
      },
      "source": [
        "inp = layers.Input(shape=(3,img_height, img_width))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n06t0Tyt78g1"
      },
      "source": [
        "x = model.conv_norm(inp, 8, kernel_size=5, strides=1, activation=CONFIG.activation)\n",
        "x = model.conv_norm(x, 32, kernel_size=3, strides=2, activation=CONFIG.activation,\n",
        "                    do_norm_act=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1JHkNIt4JIH"
      },
      "source": [
        "x = model.down_stack(x, fltrs=[ 8,16,16], self_attn=False, dp_rate=CONFIG.dp_rate)   # (64, 16, 16)\n",
        "x = model.down_stack(x, fltrs=[16,32,32], self_attn=[False, True, True], dp_rate=CONFIG.dp_rate)   # (128, 8, 8)\n",
        "x = model.down_stack(x, fltrs=[32,64,64], self_attn=True, dp_rate=CONFIG.dp_rate)   # (256, 4, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7kCNvw4D-bk"
      },
      "source": [
        "x = model.conv_norm(x, 512, kernel_size=3, strides=1, activation=CONFIG.activation)\n",
        "x = layers.GlobalAveragePooling2D(data_format=\"channels_first\")(x)\n",
        "if CONFIG.dp_rate:\n",
        "    x = layers.Dropout(CONFIG.dp_rate)(x)\n",
        "x = layers.Dense(CLASSES)(x)\n",
        "x = layers.Softmax(axis=1)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw9aIc5c4JFQ",
        "outputId": "e1ad0e05-79cb-4c46-db41-39a6cb0b1613"
      },
      "source": [
        "m = tf.keras.Model(inputs=inp, outputs=x)\n",
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 3, 64, 64)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 8, 64, 64)    608         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 8, 64, 64)    32          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 8, 64, 64)    0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   2336        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 32, 32)    264         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 8, 32, 32)    32          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 32, 32)    0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 8, 16, 16)    584         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 8, 16, 16)    32          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 16, 16)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 16, 16)   288         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d (SqueezeAtt (None, 32, 16, 16)   552         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 16, 16)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 16, 16)   0           squeeze_attention2d[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 16, 16)   0           max_pooling2d[0][0]              \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 16, 16)   128         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 16, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 16)   528         activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 16)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 16, 16)   1088        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d_1 (SqueezeA (None, 64, 16, 16)   2128        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 16, 16)   2112        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64, 16, 16)   0           squeeze_attention2d_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64, 16, 16)   0           conv2d_5[0][0]                   \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 16, 16)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 16, 16)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 16)   1040        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 16)   64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 16)   2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 16)   64          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 16, 16)   1088        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d_2 (SqueezeA (None, 64, 16, 16)   2128        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 16, 16)   4160        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64, 16, 16)   0           squeeze_attention2d_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 16, 16)   0           conv2d_9[0][0]                   \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 16, 16)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 16, 16)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 16)   1040        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 16)   64          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 16)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 8, 8)     2320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 8, 8)     64          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 8, 8)     0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 64, 8, 8)     1088        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d_3 (SqueezeA (None, 64, 8, 8)     2128        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 8, 8)     0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64, 8, 8)     0           squeeze_attention2d_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64, 8, 8)     0           max_pooling2d_1[0][0]            \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 8, 8)     256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 64, 8, 8)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 8, 8)     2080        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 8, 8)     128         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 8, 8)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 40, 8, 8)     1320        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.split (TFOpLambda)           [(None, 16, 8, 8), ( 0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 16, 8, 8)     0           tf.split[0][1]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 8, 2, 64)     0           tf.split[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 8, 2, 64)     0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer (MatMulLayer)     (None, 8, 64, 64)    0           reshape[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_positional_embeddings (AddP (None, 8, 64, 64)    128         mat_mul_layer[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 8, 1, 64)     0           tf.split[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 8, 64, 64)    0           add_positional_embeddings[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_1 (MatMulLayer)   (None, 8, 1, 64)     0           reshape_2[0][0]                  \n",
            "                                                                 softmax[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 8, 8, 8)      0           mat_mul_layer_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 8)      72          reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 24, 8, 8)     6936        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 8, 8)     0           conv2d_20[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 8, 8)     128         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 8, 8)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 128, 8, 8)    4224        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d_4 (SqueezeA (None, 128, 8, 8)    8352        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 8, 8)    8320        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 128, 8, 8)    0           squeeze_attention2d_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 128, 8, 8)    0           conv2d_16[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 8, 8)    512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 128, 8, 8)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 8, 8)     4128        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 8, 8)     128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 8, 8)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 40, 8, 8)     1320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.split_1 (TFOpLambda)         [(None, 16, 8, 8), ( 0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 16, 8, 8)     0           tf.split_1[0][1]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 8, 2, 64)     0           tf.split_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 8, 2, 64)     0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_2 (MatMulLayer)   (None, 8, 64, 64)    0           reshape_4[0][0]                  \n",
            "                                                                 reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_positional_embeddings_1 (Ad (None, 8, 64, 64)    128         mat_mul_layer_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 8, 1, 64)     0           tf.split_1[0][2]                 \n",
            "__________________________________________________________________________________________________\n",
            "softmax_1 (Softmax)             (None, 8, 64, 64)    0           add_positional_embeddings_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_3 (MatMulLayer)   (None, 8, 1, 64)     0           reshape_6[0][0]                  \n",
            "                                                                 softmax_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 8, 8, 8)      0           mat_mul_layer_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 8)      72          reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 24, 8, 8)     6936        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 8, 8)     0           conv2d_26[0][0]                  \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 8, 8)     128         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 8, 8)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 128, 8, 8)    4224        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d_5 (SqueezeA (None, 128, 8, 8)    8352        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 128, 8, 8)    16512       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 128, 8, 8)    0           squeeze_attention2d_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 128, 8, 8)    0           conv2d_22[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 128, 8, 8)    512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 128, 8, 8)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 8, 8)     4128        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 8, 8)     128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 8, 8)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 32, 4, 4)     0           activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 40, 4, 4)     1320        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.split_2 (TFOpLambda)         [(None, 16, 4, 4), ( 0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 16, 4, 4)     0           tf.split_2[0][1]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 8, 2, 16)     0           tf.split_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 8, 2, 16)     0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_4 (MatMulLayer)   (None, 8, 16, 16)    0           reshape_8[0][0]                  \n",
            "                                                                 reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_positional_embeddings_2 (Ad (None, 8, 16, 16)    32          mat_mul_layer_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 8, 1, 16)     0           tf.split_2[0][2]                 \n",
            "__________________________________________________________________________________________________\n",
            "softmax_2 (Softmax)             (None, 8, 16, 16)    0           add_positional_embeddings_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_5 (MatMulLayer)   (None, 8, 1, 16)     0           reshape_10[0][0]                 \n",
            "                                                                 softmax_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 8, 4, 4)      0           mat_mul_layer_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 4, 4)      72          reshape_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 24, 4, 4)     6936        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 4, 4)     0           conv2d_31[0][0]                  \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 4, 4)     128         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 4, 4)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 128, 4, 4)    4224        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d_6 (SqueezeA (None, 128, 4, 4)    8352        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 128, 4, 4)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 128, 4, 4)    0           squeeze_attention2d_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 128, 4, 4)    0           max_pooling2d_2[0][0]            \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 128, 4, 4)    512         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 128, 4, 4)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 64, 4, 4)     8256        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 64, 4, 4)     256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 64, 4, 4)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 80, 4, 4)     5200        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.split_3 (TFOpLambda)         [(None, 32, 4, 4), ( 0           conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 32, 4, 4)     0           tf.split_3[0][1]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 8, 4, 16)     0           tf.split_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 8, 4, 16)     0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_6 (MatMulLayer)   (None, 8, 16, 16)    0           reshape_12[0][0]                 \n",
            "                                                                 reshape_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_positional_embeddings_3 (Ad (None, 8, 16, 16)    32          mat_mul_layer_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 8, 2, 16)     0           tf.split_3[0][2]                 \n",
            "__________________________________________________________________________________________________\n",
            "softmax_3 (Softmax)             (None, 8, 16, 16)    0           add_positional_embeddings_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_7 (MatMulLayer)   (None, 8, 2, 16)     0           reshape_14[0][0]                 \n",
            "                                                                 softmax_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_15 (Reshape)            (None, 16, 4, 4)     0           mat_mul_layer_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 4, 4)     272         reshape_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 48, 4, 4)     27696       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 64, 4, 4)     0           conv2d_37[0][0]                  \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 64, 4, 4)     256         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 64, 4, 4)     0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 256, 4, 4)    16640       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d_7 (SqueezeA (None, 256, 4, 4)    33088       conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 256, 4, 4)    33024       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 256, 4, 4)    0           squeeze_attention2d_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 256, 4, 4)    0           conv2d_33[0][0]                  \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 256, 4, 4)    1024        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 256, 4, 4)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 64, 4, 4)     16448       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 64, 4, 4)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 64, 4, 4)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 80, 4, 4)     5200        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.split_4 (TFOpLambda)         [(None, 32, 4, 4), ( 0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 32, 4, 4)     0           tf.split_4[0][1]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_16 (Reshape)            (None, 8, 4, 16)     0           tf.split_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_17 (Reshape)            (None, 8, 4, 16)     0           lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_8 (MatMulLayer)   (None, 8, 16, 16)    0           reshape_16[0][0]                 \n",
            "                                                                 reshape_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_positional_embeddings_4 (Ad (None, 8, 16, 16)    32          mat_mul_layer_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_18 (Reshape)            (None, 8, 2, 16)     0           tf.split_4[0][2]                 \n",
            "__________________________________________________________________________________________________\n",
            "softmax_4 (Softmax)             (None, 8, 16, 16)    0           add_positional_embeddings_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "mat_mul_layer_9 (MatMulLayer)   (None, 8, 2, 16)     0           reshape_18[0][0]                 \n",
            "                                                                 softmax_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_19 (Reshape)            (None, 16, 4, 4)     0           mat_mul_layer_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 4, 4)     272         reshape_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 48, 4, 4)     27696       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 64, 4, 4)     0           conv2d_43[0][0]                  \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 64, 4, 4)     256         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 64, 4, 4)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 256, 4, 4)    16640       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "squeeze_attention2d_8 (SqueezeA (None, 256, 4, 4)    33088       conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 256, 4, 4)    65792       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 256, 4, 4)    0           squeeze_attention2d_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 256, 4, 4)    0           conv2d_39[0][0]                  \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 512, 4, 4)    1180160     add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 512, 4, 4)    2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 512, 4, 4)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_9 (Glo (None, 512)          0           activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 512)          0           global_average_pooling2d_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 200)          102600      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "softmax_5 (Softmax)             (None, 200)          0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,708,328\n",
            "Trainable params: 1,704,376\n",
            "Non-trainable params: 3,952\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnbTakpi4JC7"
      },
      "source": [
        "ret = tf.keras.utils.plot_model(m, to_file='model.svg', show_shapes=True, dpi=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdJakYhxsXIH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brIBUNULsXBl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHFlgYpjCEQr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs5BiKqTGJsd"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtNLrP0hGJzm"
      },
      "source": [
        "# wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXAKFpPqGJ_e"
      },
      "source": [
        "# run = wandb.init(project=\"tiny-imagenet-test\", entity=\"shivamshrirao\", config=config_defaults)\n",
        "# CONFIG = wandb.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ32ZoQVGKT-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svILsoO8GKXv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}